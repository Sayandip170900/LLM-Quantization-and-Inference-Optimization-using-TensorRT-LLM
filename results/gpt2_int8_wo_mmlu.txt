2025-05-10 14:42:17,798 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT-LLM version: 0.20.0rc1
[TensorRT-LLM][INFO] Engine version 0.20.0rc1 found in the config file, assuming engine(s) built by new builder API.
[TensorRT-LLM][INFO] MPI size: 1, MPI local size: 1, rank: 0
[TensorRT-LLM][INFO] Engine version 0.20.0rc1 found in the config file, assuming engine(s) built by new builder API.
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] MPI size: 1, MPI local size: 1, rank: 0
[TensorRT-LLM][INFO] Rank 0 is using GPU 0
[TensorRT-LLM][INFO] TRTGptModel maxNumSequences: 16
[TensorRT-LLM][INFO] TRTGptModel maxBatchSize: 16
[TensorRT-LLM][INFO] TRTGptModel maxBeamWidth: 1
[TensorRT-LLM][INFO] TRTGptModel maxSequenceLen: 1024
[TensorRT-LLM][INFO] TRTGptModel maxDraftLen: 0
[TensorRT-LLM][INFO] TRTGptModel mMaxAttentionWindowSize: (1024) * 12
[TensorRT-LLM][INFO] TRTGptModel enableTrtOverlap: 0
[TensorRT-LLM][INFO] TRTGptModel normalizeLogProbs: 1
[TensorRT-LLM][INFO] TRTGptModel maxNumTokens: 8192
[TensorRT-LLM][INFO] TRTGptModel maxInputLen: 1023 = min(maxSequenceLen - 1, maxNumTokens) since context FMHA and usePackedInput are enabled
[TensorRT-LLM][INFO] TRTGptModel If model type is encoder, maxInputLen would be reset in trtEncoderModel to maxInputLen: min(maxSequenceLen, maxNumTokens).
[TensorRT-LLM][INFO] Capacity Scheduler Policy: GUARANTEED_NO_EVICT
[TensorRT-LLM][INFO] Context Chunking Scheduler Policy: None
[TensorRT-LLM][INFO] Loaded engine size: 232 MiB
[TensorRT-LLM][INFO] Engine load time 2578 ms
[TensorRT-LLM][INFO] Inspecting the engine to identify potential runtime issues...
[TensorRT-LLM][INFO] The profiling verbosity of the engine does not allow this analysis to proceed. Re-build the engine with 'detailed' profiling verbosity to get more diagnostics.
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 120.01 MiB for execution context memory.
[TensorRT-LLM][INFO] gatherContextLogits: 0
[TensorRT-LLM][INFO] gatherGenerationLogits: 0
[TensorRT-LLM][INFO] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 230 (MiB)
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 1.88 MB GPU memory for runtime buffers.
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 8.67 MB GPU memory for decoder.
[TensorRT-LLM][INFO] Memory usage when calculating max tokens in paged kv cache: total: 15.99 GiB, available: 14.49 GiB
[TensorRT-LLM][INFO] Number of blocks in KV cache primary pool: 11868
[TensorRT-LLM][INFO] Number of blocks in KV cache secondary pool: 0, onboard blocks to primary memory before reuse: true
[TensorRT-LLM][INFO] Max KV cache pages per sequence: 32 [window size=1024]
[TensorRT-LLM][INFO] Number of tokens per block: 32.
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 13.04 GiB for max tokens in paged KV cache (379776).

  0%|          | 0/57 [00:00<?, ?it/s]
  2%|▏         | 1/57 [00:02<02:10,  2.33s/it]
  4%|▎         | 2/57 [00:03<01:35,  1.73s/it]
  5%|▌         | 3/57 [00:05<01:35,  1.77s/it]
  7%|▋         | 4/57 [00:06<01:20,  1.51s/it]
  9%|▉         | 5/57 [00:09<01:44,  2.01s/it]
 11%|█         | 6/57 [00:11<01:41,  1.99s/it]
 12%|█▏        | 7/57 [00:12<01:26,  1.72s/it]
 14%|█▍        | 8/57 [00:13<01:15,  1.54s/it]
 16%|█▌        | 9/57 [00:14<01:07,  1.40s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors

 18%|█▊        | 10/57 [00:16<01:13,  1.56s/it]
 19%|█▉        | 11/57 [00:17<01:05,  1.43s/it]
 21%|██        | 12/57 [00:19<01:00,  1.35s/it]
 23%|██▎       | 13/57 [00:21<01:16,  1.73s/it]
 25%|██▍       | 14/57 [00:23<01:10,  1.63s/it]
 26%|██▋       | 15/57 [00:24<01:06,  1.59s/it]
 28%|██▊       | 16/57 [00:30<02:03,  3.00s/it]
 30%|██▉       | 17/57 [00:32<01:45,  2.63s/it]
 32%|███▏      | 18/57 [00:33<01:27,  2.26s/it]
 33%|███▎      | 19/57 [00:38<01:46,  2.80s/it]
 35%|███▌      | 20/57 [00:40<01:42,  2.78s/it]
 37%|███▋      | 21/57 [00:42<01:27,  2.42s/it]
 39%|███▊      | 22/57 [00:48<02:07,  3.64s/it]
 40%|████      | 23/57 [00:51<01:53,  3.34s/it]
 42%|████▏     | 24/57 [00:54<01:43,  3.15s/it]
 44%|████▍     | 25/57 [00:59<02:01,  3.79s/it]
 46%|████▌     | 26/57 [01:04<02:12,  4.28s/it]
 47%|████▋     | 27/57 [01:08<01:57,  3.93s/it]
 49%|████▉     | 28/57 [01:09<01:35,  3.30s/it]
 51%|█████     | 29/57 [01:17<02:05,  4.49s/it]
 53%|█████▎    | 30/57 [01:20<01:51,  4.12s/it]
 54%|█████▍    | 31/57 [01:27<02:10,  5.03s/it]
 56%|█████▌    | 32/57 [01:32<02:07,  5.10s/it]
 58%|█████▊    | 33/57 [01:37<02:01,  5.06s/it]
 60%|█████▉    | 34/57 [01:39<01:33,  4.04s/it]
 61%|██████▏   | 35/57 [01:41<01:13,  3.32s/it]
 63%|██████▎   | 36/57 [01:42<00:57,  2.74s/it]
 65%|██████▍   | 37/57 [01:44<00:49,  2.45s/it]
 67%|██████▋   | 38/57 [01:45<00:40,  2.11s/it]
 68%|██████▊   | 39/57 [01:46<00:32,  1.80s/it]
 70%|███████   | 40/57 [01:49<00:35,  2.11s/it]
 72%|███████▏  | 41/57 [01:50<00:29,  1.83s/it]
 74%|███████▎  | 42/57 [01:59<00:57,  3.81s/it]
 75%|███████▌  | 43/57 [02:03<00:55,  3.97s/it]
 77%|███████▋  | 44/57 [02:18<01:33,  7.21s/it]
 79%|███████▉  | 45/57 [02:21<01:13,  6.17s/it]
 81%|████████  | 46/57 [02:25<00:59,  5.43s/it]
 82%|████████▏ | 47/57 [02:29<00:49,  4.94s/it]
 84%|████████▍ | 48/57 [02:33<00:41,  4.57s/it]
 86%|████████▌ | 49/57 [03:12<02:00, 15.08s/it]
 88%|████████▊ | 50/57 [03:17<01:24, 12.03s/it]
 89%|████████▉ | 51/57 [03:27<01:08, 11.41s/it]
 91%|█████████ | 52/57 [03:28<00:41,  8.40s/it]
 93%|█████████▎| 53/57 [03:33<00:29,  7.30s/it]
 95%|█████████▍| 54/57 [03:35<00:17,  5.78s/it]
 96%|█████████▋| 55/57 [03:37<00:08,  4.41s/it]
 98%|█████████▊| 56/57 [03:39<00:03,  3.67s/it]
100%|██████████| 57/57 [03:41<00:00,  3.17s/it]
100%|██████████| 57/57 [03:41<00:00,  3.88s/it]
[TensorRT-LLM][INFO] Refreshed the MPI local session
Average accuracy 0.210 - abstract_algebra
Average accuracy 0.230 - anatomy
Average accuracy 0.164 - astronomy
Average accuracy 0.160 - business_ethics
Average accuracy 0.253 - clinical_knowledge
Average accuracy 0.222 - college_biology
Average accuracy 0.260 - college_chemistry
Average accuracy 0.280 - college_computer_science
Average accuracy 0.260 - college_mathematics
Average accuracy 0.243 - college_medicine
Average accuracy 0.265 - college_physics
Average accuracy 0.120 - computer_security
Average accuracy 0.255 - conceptual_physics
Average accuracy 0.289 - econometrics
Average accuracy 0.248 - electrical_engineering
Average accuracy 0.254 - elementary_mathematics
Average accuracy 0.246 - formal_logic
Average accuracy 0.160 - global_facts
Average accuracy 0.300 - high_school_biology
Average accuracy 0.261 - high_school_chemistry
Average accuracy 0.240 - high_school_computer_science
Average accuracy 0.315 - high_school_european_history
Average accuracy 0.354 - high_school_geography
Average accuracy 0.368 - high_school_government_and_politics
Average accuracy 0.287 - high_school_macroeconomics
Average accuracy 0.241 - high_school_mathematics
Average accuracy 0.298 - high_school_microeconomics
Average accuracy 0.252 - high_school_physics
Average accuracy 0.349 - high_school_psychology
Average accuracy 0.472 - high_school_statistics
Average accuracy 0.250 - high_school_us_history
Average accuracy 0.207 - high_school_world_history
Average accuracy 0.265 - human_aging
Average accuracy 0.260 - human_sexuality
Average accuracy 0.306 - international_law
Average accuracy 0.213 - jurisprudence
Average accuracy 0.233 - logical_fallacies
Average accuracy 0.188 - machine_learning
Average accuracy 0.359 - management
Average accuracy 0.197 - marketing
Average accuracy 0.270 - medical_genetics
Average accuracy 0.232 - miscellaneous
Average accuracy 0.197 - moral_disputes
Average accuracy 0.242 - moral_scenarios
Average accuracy 0.225 - nutrition
Average accuracy 0.254 - philosophy
Average accuracy 0.225 - prehistory
Average accuracy 0.273 - professional_accounting
Average accuracy 0.263 - professional_law
Average accuracy 0.438 - professional_medicine
Average accuracy 0.261 - professional_psychology
Average accuracy 0.182 - public_relations
Average accuracy 0.388 - security_studies
Average accuracy 0.229 - sociology
Average accuracy 0.270 - us_foreign_policy
Average accuracy 0.199 - virology
Average accuracy 0.205 - world_religions
Average accuracy 29.14 - math
Average accuracy 27.26 - health
Average accuracy 23.44 - physics
Average accuracy 22.65 - business
Average accuracy 27.53 - biology
Average accuracy 26.07 - chemistry
Average accuracy 20.63 - computer science
Average accuracy 29.11 - economics
Average accuracy 24.83 - engineering
Average accuracy 23.26 - philosophy
Average accuracy 23.61 - other
Average accuracy 24.19 - history
Average accuracy 35.35 - geography
Average accuracy 32.87 - politics
Average accuracy 30.25 - psychology
Average accuracy 24.10 - culture
Average accuracy 26.26 - law
Average accuracy 26.01 - STEM
Average accuracy 24.57 - humanities
Average accuracy 30.19 - social sciences
Average accuracy 25.32 - other (business, health, misc.)
MMLU weighted average accuracy: 26.29
