2025-05-11 10:13:41,781 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT-LLM version: 0.20.0rc1
Allocated 644.13 MiB for execution context memory.
/mnt/c/Users/spal6554/pytorch/venvnn/lib/python3.12/site-packages/torch/nested/__init__.py:228: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)
  return _nested.nested_tensor(
2025-05-11 10:15:45,737 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT-LLM version: 0.20.0rc1
[BENCHMARK] engine_dir Llama-2-7b-hf_full_prec world_size 1 num_heads 32 num_kv_heads 32 num_layers 32 hidden_size 4096 vocab_size 32000 precision float16 batch_size 16 gpu_weights_percent 1.0 input_length 128 output_length 20 gpu_peak_mem(gb) 15.499 build_time(s) None tokens_per_sec 219.72 percentile95(ms) 1481.018 percentile99(ms) 1481.713 latency(ms) 1456.402 compute_cap sm86 quantization 0 generation_time(ms) 882.023 total_generated_tokens 304.0 generation_tokens_per_second 344.662
